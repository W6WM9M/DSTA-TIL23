{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "V7rt5xiffndp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install timm"
      ],
      "metadata": {
        "id": "hLA5o2zVh_DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --folder https://drive.google.com/drive/folders/115l82GBgu6RETopB_Qy36hn4TVwXI2t5?usp=sharing"
      ],
      "metadata": {
        "id": "hm6k0O9sfplB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/Datasets\"\n",
        "!mkdir \"/content/Datasets/images\"\n",
        "!mkdir \"/content/Datasets/images/train\"\n",
        "!mkdir \"/content/Datasets/images/val\"\n",
        "!mkdir \"/content/Datasets/images/test\"\n",
        "!mkdir \"/content/Datasets/labels\"\n",
        "!mkdir \"/content/Datasets/labels/val\"\n",
        "!mkdir \"/content/Datasets/labels/train\"\n",
        "\n",
        "!unzip \"/content/Advanced/CV/Train.zip\" -d \"/content/Datasets/images/train\"\n",
        "!unzip \"/content/Advanced/CV/Validation.zip\" -d \"/content/Datasets/images/val\"\n",
        "!unzip \"/content/Advanced/CV/Test.zip\" -d \"/content/Datasets/images/test\"\n",
        "\n",
        "!unzip \"/content/Advanced/CV/train_labels.zip\" -d \"/content/Datasets/labels/train\"\n",
        "!unzip \"/content/Advanced/CV/val_labels.zip\" -d \"/content/Datasets/labels/val\""
      ],
      "metadata": {
        "id": "FMiROQg9ftWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm \n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "ROOT = r\".\" # Change this as required - tmp location\n",
        "train_images_path = \"/content/Datasets/images/train\" \n",
        "train_labels_path = \"/content/Datasets/labels/train\" \n",
        "val_images_path = \"/content/Datasets/images/val\"\n",
        "val_labels_path = \"/content/Datasets/labels/val\"\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "DxGtHrwCWDhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generate Folders for Train Crops and Validation Crops**"
      ],
      "metadata": {
        "id": "H-9QKy7eW5Et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_crops_path = ROOT + \"/REID_Data/train\" # Change this as required\n",
        "num_plushies = 200\n",
        "try:\n",
        "    os.mkdir(train_crops_path)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "for i in range(num_plushies):\n",
        "    os.mkdir(train_crops_path + f\"/{i}\")\n",
        "\n",
        "val_crops_path = ROOT + \"/REID_Data/val\" # Change this as required\n",
        "num_plushies = 10\n",
        "\n",
        "try:\n",
        "    os.mkdir(val_crops_path)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "for i in range(num_plushies):\n",
        "    os.mkdir(val_crops_path + f\"/{i}\")"
      ],
      "metadata": {
        "id": "IQxSJMVkWGPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generate Train and Validation Crops**"
      ],
      "metadata": {
        "id": "iwjCJzhpW8Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "images_path = train_images_path\n",
        "labels_path = train_labels_path\n",
        "annotated_images_path = train_crops_path\n",
        "\n",
        "\n",
        "for label_name in tqdm(os.listdir(labels_path)):\n",
        "    if label_name[-4:] != \".txt\":\n",
        "        continue\n",
        "    image_name = label_name[:-4] + \".png\"\n",
        "    # print(\"Checking\", image_name)\n",
        "\n",
        "    image_path = os.path.join(images_path, image_name)\n",
        "    label_path = os.path.join(labels_path, label_name)\n",
        "\n",
        "    df = pd.read_csv(label_path, delim_whitespace=True, header=None)\n",
        "    df.columns = [\"cat\", \"xc\", \"yc\", \"w\", \"h\"]\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    img_h, img_w = img.shape[:2]\n",
        "\n",
        "    for i in range(df.shape[0]):\n",
        "        bb = df.iloc[i]\n",
        "        cat = str(int(bb[\"cat\"]))\n",
        "        tl = (int((bb[\"xc\"] - bb[\"w\"]/2) * img_w), int((bb[\"yc\"] - bb[\"h\"]/2) * img_h))\n",
        "        br = (int((bb[\"xc\"] + bb[\"w\"]/2) * img_w), int((bb[\"yc\"] + bb[\"h\"]/2) * img_h))\n",
        "\n",
        "        cropped_img = img[tl[1]:br[1], tl[0]:br[0]]\n",
        "        annotated_img_name = f\"{cat}_{len(os.listdir(os.path.join(annotated_images_path, cat)))}.png\"\n",
        "        cv2.imwrite(os.path.join(annotated_images_path, cat, annotated_img_name), cropped_img)"
      ],
      "metadata": {
        "id": "dKL9P0dvWX3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = val_images_path\n",
        "labels_path = val_labels_path\n",
        "annotated_images_path = val_crops_path\n",
        "\n",
        "\n",
        "for label_name in tqdm(os.listdir(labels_path)):\n",
        "    if label_name[-4:] != \".txt\":\n",
        "        continue\n",
        "    image_name = label_name[:-4] + \".png\"\n",
        "#     print(\"Checking\", image_name)\n",
        "\n",
        "    image_path = os.path.join(images_path, image_name)\n",
        "    label_path = os.path.join(labels_path, label_name)\n",
        "\n",
        "    df = pd.read_csv(label_path, delim_whitespace=True, header=None)\n",
        "    df.columns = [\"cat\", \"xc\", \"yc\", \"w\", \"h\"]\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    img_h, img_w = img.shape[:2]\n",
        "\n",
        "    for i in range(df.shape[0]):\n",
        "        bb = df.iloc[i]\n",
        "        cat = str(int(bb[\"cat\"]))\n",
        "        tl = (int((bb[\"xc\"] - bb[\"w\"]/2) * img_w), int((bb[\"yc\"] - bb[\"h\"]/2) * img_h))\n",
        "        br = (int((bb[\"xc\"] + bb[\"w\"]/2) * img_w), int((bb[\"yc\"] + bb[\"h\"]/2) * img_h))\n",
        "\n",
        "        cropped_img = img[tl[1]:br[1], tl[0]:br[0]]\n",
        "        annotated_img_name = f\"{cat}_{len(os.listdir(os.path.join(annotated_images_path, cat)))}.png\"\n",
        "        cv2.imwrite(os.path.join(annotated_images_path, cat, annotated_img_name), cropped_img)"
      ],
      "metadata": {
        "id": "TNwSwItxWZQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generate Train Matched and Non Matched Pairs**"
      ],
      "metadata": {
        "id": "002r_VTRWdyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = {}\n",
        "\n",
        "crops_path = train_crops_path\n",
        "num_plushies = 200\n",
        "print(\"Train Set\")\n",
        "for i in range(num_plushies):\n",
        "    counts[i] = len(os.listdir(os.path.join(crops_path, str(i))))\n",
        "print(counts)\n",
        "\n",
        "def generate_matched_pairs(count):\n",
        "    matched_df = pd.DataFrame(columns = [\"img1\", \"img2\"])\n",
        "    matched_dict = {k: [] for k in counts.keys()}\n",
        "    \n",
        "    for i in tqdm(range(count)):\n",
        "        plushie = random.choice(list(counts.keys()))    \n",
        "        num1, num2 = random.randrange(counts[plushie]), random.randrange(counts[plushie])\n",
        "        \n",
        "        while set([num1, num2]) in matched_dict[plushie]:\n",
        "            plushie = random.choice(list(counts.keys()))\n",
        "            num1, num2 = random.randrange(counts[plushie]), random.randrange(counts[plushie])\n",
        "        \n",
        "        matched_dict[plushie].append(set([num1, num2]))\n",
        "        matched_df.loc[i] = [f\"{plushie}/{plushie}_{num1}.png\", f\"{plushie}/{plushie}_{num2}.png\"]\n",
        "    \n",
        "    return matched_df\n",
        "        \n",
        "\n",
        "def generate_non_matched_pairs(count):\n",
        "    df = pd.DataFrame(columns = [\"img1\", \"img2\"])\n",
        "    \n",
        "    for i in tqdm(range(count)):\n",
        "        plushie1 = random.choice(list(counts.keys()))\n",
        "        plushie2 = random.choice(list(counts.keys()))\n",
        "        while plushie1 == plushie2:\n",
        "            plushie1 = random.choice(list(counts.keys()))\n",
        "            plushie2 = random.choice(list(counts.keys()))\n",
        "            \n",
        "        num1, num2 = random.randrange(counts[plushie1]), random.randrange(counts[plushie2])\n",
        "        \n",
        "        if len(df[df['img1'] == f\"{plushie1}/{plushie1}_{num1}.png\"]) > 0:\n",
        "            while f\"{plushie2}/{plushie2}_{num2}.png\" in df[df['img1'] == f\"{plushie1}/{plushie1}_{num1}.png\"]['img2'].values:\n",
        "                num1, num2 = random.randrange(counts[plushie1]), random.randrange(counts[plushie2])\n",
        "        \n",
        "        df.loc[i] = [f\"{plushie1}/{plushie1}_{num1}.png\", f\"{plushie2}/{plushie2}_{num2}.png\"]\n",
        "    \n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "matched_df = generate_matched_pairs(30000)\n",
        "matched_df.to_csv(ROOT + \"/matched_pairs_train.csv\",index=False)\n",
        "   \n",
        "non_matched_df = generate_non_matched_pairs(30000)\n",
        "non_matched_df.to_csv(ROOT + \"/non_matched_pairs_train.csv\", index = False)\n"
      ],
      "metadata": {
        "id": "ujhNeeXtWbWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generate Validation Matched and Non Matched Pairs**"
      ],
      "metadata": {
        "id": "sjMUdzFWWqoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = {}\n",
        "print(\"Validation Set\")\n",
        "crops_path = val_crops_path\n",
        "num_plushies = 10\n",
        "\n",
        "for i in range(num_plushies):\n",
        "    counts[i] = len(os.listdir(os.path.join(crops_path, str(i))))\n",
        "print(counts)\n",
        "\n",
        "matched_df = generate_matched_pairs(6000)\n",
        "matched_df.to_csv(ROOT + \"/matched_pairs_val.csv\",index=False)\n",
        "\n",
        "non_matched_df = generate_non_matched_pairs(6000)\n",
        "non_matched_df.to_csv(ROOT + \"/non_matched_pairs_val.csv\",index=False)"
      ],
      "metadata": {
        "id": "jK0rCBqWWsZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gwn_HwrfUjrN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "from torch import nn, optim\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "def load_data(train_ds_path, test_ds_path):\n",
        "    \n",
        "    train_ds = torch.load(train_ds_path).to(device)\n",
        "    val_ds = torch.load(test_ds_path).to(device)\n",
        "    \n",
        "    # 1 - Matched, 0 - Non-Matched\n",
        "    train_label = torch.zeros(size = (train_ds.shape[0], 1)).to(device)\n",
        "    for i in range(train_ds.shape[0]//2):\n",
        "        train_label[i] = torch.tensor([1])\n",
        "        \n",
        "    \n",
        "    val_label = torch.zeros(size = (val_ds.shape[0], 1)).to(device)\n",
        "    for i in range(val_ds.shape[0]//2):\n",
        "        val_label[i] = torch.tensor([1])\n",
        "        \n",
        "    print(f\"X Train: {train_ds.shape}\")\n",
        "    print(f\"X Val: {val_ds.shape}\")\n",
        "    print(f\"y Train: {train_label.shape}\")\n",
        "    print(f\"y Val: {val_label.shape}\")\n",
        "    \n",
        "\n",
        "    return train_ds, train_label, val_ds, val_label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference: https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch\n",
        "class EarlyStopper_Checkpoint():\n",
        "    def __init__(self, patience=1, save_path = None, min_delta=0, metric = \"val_loss\"):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.save_path = save_path\n",
        "        self.metric = metric\n",
        "        if metric == \"val_loss\":\n",
        "            self.min_validation_loss = np.inf\n",
        "        elif metric == \"val_acc\":\n",
        "            self.max_validation_accuracy = 0\n",
        "\n",
        "    def early_stop(self, metric):\n",
        "        if self.metric == \"val_loss\":\n",
        "            if self.check_metric(metric):\n",
        "                self.min_validation_loss = metric\n",
        "                self.counter = 0\n",
        "            elif metric > (self.min_validation_loss + self.min_delta):\n",
        "                self.counter += 1\n",
        "                if self.counter >= self.patience:\n",
        "                    return True\n",
        "            return False\n",
        "        elif self.metric == \"val_acc\":\n",
        "            if self.check_metric(metric):\n",
        "                self.max_validation_accuracy = metric\n",
        "                self.counter = 0\n",
        "            elif metric < (self.max_validation_accuracy + self.min_delta):\n",
        "                self.counter += 1\n",
        "                if self.counter >= self.patience:\n",
        "                    return True\n",
        "            return False\n",
        "            \n",
        "    def check_metric(self, metric):\n",
        "        if self.metric == \"val_loss\":\n",
        "            if metric < self.min_validation_loss:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        elif self.metric == \"val_acc\":\n",
        "            if metric > self.max_validation_accuracy:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "    \n",
        "class NN_Classifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NN_Classifier, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        output = self.linear_relu_stack(x)\n",
        "        return output\n",
        "\n",
        "def ema_loss(cur_loss, prev_loss):\n",
        "    loss = 0.9 * prev_loss + 0.1 * cur_loss\n",
        "    return loss\n",
        "\n",
        "\n",
        "def signed_sqrt(x1, x2):\n",
        "    return torch.sign(x1*x2) * torch.sqrt(torch.abs(x1*x2))\n",
        "    \n",
        "def combine_function(x1, x2):\n",
        "    return torch.concatenate([x1 + x2, x1 - x2, x2 -x1, x1**2 + x2**2, x1*x2, signed_sqrt(x1,x2)], axis = -1)\n"
      ],
      "metadata": {
        "id": "0vNS9TYDU3UQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert images into RESNet/SENet/ViT features and save them**"
      ],
      "metadata": {
        "id": "YSGE9E5hXOGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "from transformers import  AutoImageProcessor, ResNetModel, ViTImageProcessor, ViTModel\n",
        "import torch\n",
        "import urllib\n",
        "import timm\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "\n",
        "class BGR2RGB:\n",
        "    def __call__(self, image):\n",
        "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "class SquarePad:\n",
        "    def __call__(self, image):\n",
        "        max_wh = max(image.shape[:2])\n",
        "        p_top, p_left = [(max_wh - s) // 2 for s in image.shape[:2]]\n",
        "        p_bottom, p_right = [max_wh - (s+pad) for s, pad in zip(image.shape[:2], [p_top,p_left])]\n",
        "        return cv2.copyMakeBorder(image, p_top, p_bottom, p_left, p_right, cv2.BORDER_CONSTANT, None, value = 0)\n",
        "\n",
        "def load_feature_extractor(model_name):\n",
        "    if model_name == \"resnet\":\n",
        "        model = ResNetModel.from_pretrained(\"microsoft/resnet-50\").eval().to(device)\n",
        "        transform = transforms.Compose([BGR2RGB(),\n",
        "            SquarePad(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "        return model, transform \n",
        "\n",
        "    elif model_name == \"vit\":\n",
        "        processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "        model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k').eval().to(device)\n",
        "        return model, processor\n",
        "\n",
        "    elif model_name == \"senet\":\n",
        "        model = timm.create_model('seresnet152d', pretrained=True,num_classes = 0).eval().to(device)\n",
        "        config = resolve_data_config({}, model=model)\n",
        "        transform = create_transform(**config)\n",
        "        return model, transform"
      ],
      "metadata": {
        "id": "6obESjiIXM9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, processor = load_feature_extractor(\"resnet\")"
      ],
      "metadata": {
        "id": "7ElKTmmAZSg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_train_path = ROOT + \"/REID_Data/resnet_train\"\n",
        "\n",
        "try:\n",
        "    os.mkdir(resnet_train_path)\n",
        "except:\n",
        "    print(\"resnet_train folder exists\")\n",
        "\n",
        "for plushie in os.listdir(train_crops_path):\n",
        "    try:\n",
        "        os.mkdir(ROOT + f\"/REID_Data/resnet_train/{plushie}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "for plushie in tqdm(os.listdir(train_crops_path)):\n",
        "    for img_name in os.listdir(train_crops_path + f\"/{plushie}\"):\n",
        "        input_image = cv2.imread(train_crops_path + f\"/{plushie}/{img_name}\")\n",
        "        input_ = processor(input_image).reshape(1, 3, 224, 224)\n",
        "        with torch.no_grad():\n",
        "            output_ = model(input_, )['pooler_output'].flatten()\n",
        "            torch.save(output_, resnet_train_path + f\"/{plushie}/{img_name[:-4]}.pt\")\n",
        "        "
      ],
      "metadata": {
        "id": "yuCMxoMYXeLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_val_path = ROOT + \"/REID_Data/resnet_val\"\n",
        "\n",
        "try:\n",
        "    os.mkdir(resnet_val_path)\n",
        "except:\n",
        "    print(\"resnet_val folder exists\")\n",
        "\n",
        "for plushie in os.listdir(val_crops_path):\n",
        "    try:\n",
        "        os.mkdir(resnet_val_path + f\"/{plushie}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "for plushie in tqdm(os.listdir(val_crops_path)):\n",
        "    for img_name in os.listdir(val_crops_path + f\"/{plushie}\"):\n",
        "        input_image = cv2.imread(val_crops_path + f\"/{plushie}/{img_name}\")\n",
        "        input_ = processor(input_image).reshape(1, 3, 224, 224)\n",
        "        with torch.no_grad():\n",
        "            output_ = model(input_, )['pooler_output'].flatten()\n",
        "            torch.save(output_, resnet_val_path + f\"/{plushie}/{img_name[:-4]}.pt\")\n",
        "   "
      ],
      "metadata": {
        "id": "bSQOLd2ZXZUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, processor = load_feature_extractor(\"vit\")"
      ],
      "metadata": {
        "id": "h-RGjrqZZM9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_train_path = ROOT + \"/REID_Data/vit_train\"\n",
        "\n",
        "try:\n",
        "    os.mkdir(vit_train_path)\n",
        "except:\n",
        "    print(\"vit_train folder exists\")\n",
        "\n",
        "for plushie in os.listdir(train_crops_path):\n",
        "    try:\n",
        "        os.mkdir(ROOT + f\"/REID_Data/vit_train/{plushie}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "for plushie in tqdm(os.listdir(train_crops_path)):\n",
        "    for img_name in os.listdir(train_crops_path + f\"/{plushie}\"):\n",
        "        input_image = cv2.imread(train_crops_path + f\"/{plushie}/{img_name}\")\n",
        "        input_ = processor(BGR2RGB()(input_image), return_tensors = \"pt\")['pixel_values'][0].reshape(1, 3, 224, 224)\n",
        "        with torch.no_grad():\n",
        "            output_ = model(input_, )['pooler_output'].flatten()\n",
        "            torch.save(output_, vit_train_path + f\"/{plushie}/{img_name[:-4]}.pt\")\n",
        "        "
      ],
      "metadata": {
        "id": "YVN40rR0Xaig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_val_path = ROOT + \"/REID_Data/vit_val\"\n",
        "\n",
        "try:\n",
        "    os.mkdir(vit_val_path)\n",
        "except:\n",
        "    print(\"vit_val folder exists\")\n",
        "\n",
        "for plushie in os.listdir(val_crops_path):\n",
        "    try:\n",
        "        os.mkdir(vit_val_path + f\"/{plushie}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "for plushie in tqdm(os.listdir(val_crops_path)):\n",
        "    for img_name in os.listdir(val_crops_path + f\"/{plushie}\"):\n",
        "        input_image = cv2.imread(val_crops_path + f\"/{plushie}/{img_name}\")\n",
        "        input_ = processor(BGR2RGB()(input_image), return_tensors = \"pt\")['pixel_values'][0].reshape(1, 3, 224, 224)\n",
        "        with torch.no_grad():\n",
        "            output_ = model(input_, )['pooler_output'].flatten()\n",
        "            torch.save(output_, vit_val_path + f\"/{plushie}/{img_name[:-4]}.pt\")\n",
        "   \n",
        "    "
      ],
      "metadata": {
        "id": "Am3UwcsCXgLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, processor = load_feature_extractor(\"senet\")"
      ],
      "metadata": {
        "id": "0PGlv4fzY0NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "senet_train_path = ROOT + \"/REID_Data/senet_train\"\n",
        "try:\n",
        "    os.mkdir(senet_train_path)\n",
        "except:\n",
        "    print(\"senet_train folder exists\")\n",
        "\n",
        "for plushie in os.listdir(train_crops_path):\n",
        "    try:\n",
        "        os.mkdir(ROOT + f\"/REID_Data/senet_train/{plushie}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "for plushie in tqdm(os.listdir(train_crops_path)):\n",
        "    for img_name in os.listdir(train_crops_path + f\"/{plushie}\"):\n",
        "        input_image = Image.open(train_crops_path + f\"/{plushie}/{img_name}\").convert('RGB')\n",
        "        input_ = processor(input_image).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            output_ = model(input_).flatten()\n",
        "            torch.save(output_, senet_train_path + f\"/{plushie}/{img_name[:-4]}.pt\")\n",
        "        "
      ],
      "metadata": {
        "id": "3Zyy6U9kXhRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "senet_val_path = ROOT + \"/REID_Data/senet_val\"\n",
        "try:\n",
        "    os.mkdir(senet_val_path)\n",
        "except:\n",
        "    print(\"senet_val folder exists\")\n",
        "\n",
        "for plushie in os.listdir(val_crops_path):\n",
        "    try:\n",
        "        os.mkdir(ROOT + f\"/REID_Data/senet_val/{plushie}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "for plushie in tqdm(os.listdir(val_crops_path)):\n",
        "    for img_name in os.listdir(val_crops_path + f\"/{plushie}\"):\n",
        "        input_image = Image.open(val_crops_path + f\"/{plushie}/{img_name}\").convert('RGB')\n",
        "        input_ = processor(input_image).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            output_ = model(input_).flatten()\n",
        "            torch.save(output_, senet_val_path + f\"/{plushie}/{img_name[:-4]}.pt\")\n",
        "        "
      ],
      "metadata": {
        "id": "1bXrkBy6X9EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generate Train and Validation Dataset Tensor**\n",
        "This is so that it will be faster to load the dataset for training the neural network later on. "
      ],
      "metadata": {
        "id": "3J9gfihlZj4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv_matched = pd.read_csv(ROOT + \"/matched_pairs_train.csv\")\n",
        "train_csv_non_matched = pd.read_csv(ROOT + \"/non_matched_pairs_train.csv\")\n",
        "\n",
        "val_csv_matched =  pd.read_csv(ROOT + \"/matched_pairs_val.csv\")\n",
        "val_csv_non_matched =  pd.read_csv(ROOT + \"/non_matched_pairs_val.csv\")\n",
        "\n",
        "def save_dataset_as_tensor(csv_matched, csv_non_matched, path, total_size, dim):\n",
        "    dataset = torch.empty(size = (total_size, 2, dim))\n",
        "    \n",
        "    for i in tqdm(range(0 , len(csv_matched))):\n",
        "        img1 = torch.load(path + f\"/{csv_matched['img1'][i][:-4]}.pt\", map_location=device).reshape(1, -1)\n",
        "        img2 = torch.load(path + f\"/{csv_matched['img2'][i][:-4]}.pt\", map_location=device).reshape(1, -1)\n",
        "        input_ = torch.concat([img1, img2], dim = 0).reshape(1, 2, -1)\n",
        "        dataset[i] = input_\n",
        "    \n",
        "    for i in tqdm(range(0, len(csv_non_matched))):\n",
        "        img1 = torch.load(path + f\"/{csv_non_matched['img1'][i][:-4]}.pt\", map_location=device).reshape(1, -1)\n",
        "        img2 = torch.load(path + f\"/{csv_non_matched['img2'][i][:-4]}.pt\", map_location=device).reshape(1, -1)\n",
        "        input_ = torch.concat([img1, img2], dim = 0).reshape(1, 2, -1)\n",
        "        dataset[len(csv_matched) + i] = input_\n",
        "    \n",
        "    return dataset    "
      ],
      "metadata": {
        "id": "1zdVKwEzZfzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = ROOT + \"/REID_Data/resnet_train\"\n",
        "\n",
        "dataset = save_dataset_as_tensor(train_csv_matched, train_csv_non_matched, path, 60000, 2048)\n",
        "torch.save(dataset, ROOT + \"/train_ds_resnet.pt\")\n",
        "\n",
        "path = ROOT + \"/REID_Data/resnet_val\"\n",
        "\n",
        "dataset = save_dataset_as_tensor(val_csv_matched, val_csv_non_matched, path, 12000, 2048)\n",
        "torch.save(dataset, ROOT + \"/val_ds_resnet.pt\")"
      ],
      "metadata": {
        "id": "fjBaevaxaJHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = ROOT + \"/REID_Data/senet_train\"\n",
        "\n",
        "dataset = save_dataset_as_tensor(train_csv_matched, train_csv_non_matched, path, 60000, 2048)\n",
        "torch.save(dataset, ROOT + \"/train_ds_senet.pt\")\n",
        "\n",
        "path = ROOT + \"/REID_Data/senet_val\"\n",
        "\n",
        "dataset = save_dataset_as_tensor(val_csv_matched, val_csv_non_matched, path, 12000, 2048)\n",
        "torch.save(dataset, ROOT + \"/val_ds_senet.pt\")"
      ],
      "metadata": {
        "id": "Jvy36vtRaJoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = ROOT + \"/REID_Data/vit_train\"\n",
        "\n",
        "dataset = save_dataset_as_tensor(train_csv_matched, train_csv_non_matched, path, 60000, 768)\n",
        "torch.save(dataset, ROOT + \"/train_ds_vit.pt\")\n",
        "\n",
        "path = ROOT + \"/REID_Data/vit_val\"\n",
        "\n",
        "dataset = save_dataset_as_tensor(val_csv_matched, val_csv_non_matched, path, 12000, 768)\n",
        "torch.save(dataset, ROOT + \"/val_ds_vit.pt\")"
      ],
      "metadata": {
        "id": "coFxDywVZuc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Neural Network Classifier on RESNet Features**"
      ],
      "metadata": {
        "id": "8R_fwvZ0VAPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_val, y_val = load_data(ROOT + \"/train_ds_resnet.pt\", ROOT + \"/val_ds_resnet.pt\")\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "dataloader_train = DataLoader(TensorDataset(X_train, y_train.float()), \n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "dataloader_val =  DataLoader(TensorDataset(X_val, y_val.float()), \n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "\n",
        "model = NN_Classifier(2048 * 6, 2048, 1).to(device)\n",
        "\n",
        "checkpoint_name = f\"resnet\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "no_of_epoch = 100\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay=3e-4)\n",
        "scheduler = LinearLR(optimizer, start_factor=1, end_factor = 0.2, total_iters=50)\n",
        "start_epoch = 0\n",
        "early_stopper = EarlyStopper_Checkpoint(patience = 5, \n",
        "                                        save_path =  ROOT + f\"/{checkpoint_name}_best.pt\",\n",
        "                                        metric = \"val_acc\")\n",
        "bce_loss_func = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + no_of_epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Training \n",
        "    model.train()\n",
        "    for train_data, train_label in tqdm(dataloader_train):\n",
        "        train_data = combine_function(train_data[:,0,:], train_data[:,1,:])\n",
        "        optimizer.zero_grad()\n",
        "        output= model(train_data)\n",
        "        loss = bce_loss_func(output, train_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss = ema_loss(loss, train_loss)\n",
        "\n",
        "        y_pred = nn.Sigmoid()(output.detach())\n",
        "\n",
        "        correct += ((y_pred>0.5).float() == train_label).float().sum()\n",
        "\n",
        "    train_accuracy = correct / len(dataloader_train.dataset) * 100\n",
        "    checkpoint = {\"epoch\": epoch,\n",
        "                  \"model_state_dict\": model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'scheduler_state_dict': scheduler.state_dict()}\n",
        "    torch.save(checkpoint, ROOT + f\"/{checkpoint_name}.pt\")\n",
        "\n",
        "    print(f\"Saving checkpoint to {checkpoint_name}.pt\")\n",
        "    \n",
        "    correct = 0\n",
        "    val_loss = 0\n",
        "    \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for val_data, val_label in tqdm(dataloader_val):\n",
        "            val_data = combine_function(val_data[:,0,:], val_data[:,1,:])\n",
        "            output= model(val_data)\n",
        "            loss = bce_loss_func(output, val_label)\n",
        "            y_pred = nn.Sigmoid()(output)\n",
        "            val_loss = ema_loss(loss, val_loss)\n",
        "            correct += ((y_pred>0.5).float() == val_label).float().sum()\n",
        "\n",
        "        val_accuracy = correct / len(dataloader_val.dataset) * 100\n",
        "        print(f\"Epoch {epoch}: Train Loss: {train_loss: .5f}, Training Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss: .5f}, Val Accuracy = {val_accuracy:.2f}%\")\n",
        "\n",
        "    scheduler.step()\n",
        "    if early_stopper.check_metric(val_accuracy):\n",
        "        checkpoint = {\"epoch\": epoch,\n",
        "                      \"val_loss\": val_loss,\n",
        "                      \"val_accuracy\": val_accuracy,\n",
        "                      \"model_state_dict\": model.state_dict(),\n",
        "                      'optimizer_state_dict': optimizer.state_dict(),\n",
        "                      'scheduler_state_dict': scheduler.state_dict()}\n",
        "        \n",
        "        torch.save(checkpoint, ROOT + f\"/{checkpoint_name}_best.pt\")\n",
        "        print(f\"Saving checkpoint to {checkpoint_name}_best.pt\")\n",
        "\n",
        "\n",
        "    if early_stopper.early_stop(val_accuracy):\n",
        "        print(\"Stopped early due to no improvement in validation loss\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "BicXKwbKU_DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Neural Network Classifier on SENet Features**"
      ],
      "metadata": {
        "id": "27Dz7EBVVlkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_val, y_val = load_data(ROOT + \"/train_ds_senet.pt\", ROOT + \"/val_ds_senet.pt\")\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "dataloader_train = DataLoader(TensorDataset(X_train, y_train.float()), \n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "dataloader_val =  DataLoader(TensorDataset(X_val, y_val.float()), \n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "\n",
        "model = NN_Classifier(2048 * 6, 2048, 1).to(device)\n",
        "\n",
        "checkpoint_name = f\"senet\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "no_of_epoch = 100\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay=3e-4)\n",
        "scheduler = LinearLR(optimizer, start_factor=1, end_factor = 0.2, total_iters=50)\n",
        "start_epoch = 0\n",
        "early_stopper = EarlyStopper_Checkpoint(patience = 5, \n",
        "                                        save_path =  ROOT + f\"/{checkpoint_name}_best.pt\",\n",
        "                                        metric = \"val_acc\")\n",
        "bce_loss_func = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + no_of_epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Training \n",
        "    model.train()\n",
        "    for train_data, train_label in tqdm(dataloader_train):\n",
        "        train_data = combine_function(train_data[:,0,:], train_data[:,1,:])\n",
        "        optimizer.zero_grad()\n",
        "        output= model(train_data)\n",
        "        loss = bce_loss_func(output, train_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss = ema_loss(loss, train_loss)\n",
        "\n",
        "        y_pred = nn.Sigmoid()(output.detach())\n",
        "\n",
        "        correct += ((y_pred>0.5).float() == train_label).float().sum()\n",
        "\n",
        "    train_accuracy = correct / len(dataloader_train.dataset) * 100\n",
        "    checkpoint = {\"epoch\": epoch,\n",
        "                  \"model_state_dict\": model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'scheduler_state_dict': scheduler.state_dict()}\n",
        "    torch.save(checkpoint, ROOT + f\"/{checkpoint_name}.pt\")\n",
        "\n",
        "    print(f\"Saving checkpoint to {checkpoint_name}.pt\")\n",
        "    \n",
        "    correct = 0\n",
        "    val_loss = 0\n",
        "    \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for val_data, val_label in tqdm(dataloader_val):\n",
        "            val_data = combine_function(val_data[:,0,:], val_data[:,1,:])\n",
        "            output= model(val_data)\n",
        "            loss = bce_loss_func(output, val_label)\n",
        "            y_pred = nn.Sigmoid()(output)\n",
        "            val_loss = ema_loss(loss, val_loss)\n",
        "            correct += ((y_pred>0.5).float() == val_label).float().sum()\n",
        "\n",
        "        val_accuracy = correct / len(dataloader_val.dataset) * 100\n",
        "        print(f\"Epoch {epoch}: Train Loss: {train_loss: .5f}, Training Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss: .5f}, Val Accuracy = {val_accuracy:.2f}%\")\n",
        "\n",
        "    scheduler.step()\n",
        "    if early_stopper.check_metric(val_accuracy):\n",
        "        checkpoint = {\"epoch\": epoch,\n",
        "                      \"val_loss\": val_loss,\n",
        "                      \"val_accuracy\": val_accuracy,\n",
        "                      \"model_state_dict\": model.state_dict(),\n",
        "                      'optimizer_state_dict': optimizer.state_dict(),\n",
        "                      'scheduler_state_dict': scheduler.state_dict()}\n",
        "        \n",
        "        torch.save(checkpoint, ROOT + f\"/{checkpoint_name}_best.pt\")\n",
        "        print(f\"Saving checkpoint to {checkpoint_name}_best.pt\")\n",
        "\n",
        "\n",
        "    if early_stopper.early_stop(val_accuracy):\n",
        "        print(\"Stopped early due to no improvement in validation loss\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "U979Q8c3U-vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Neural Network Classifier on Vision Transformer Features**"
      ],
      "metadata": {
        "id": "lUXk8-G7VtbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_val, y_val = load_data(ROOT + \"/train_ds_vit.pt\", ROOT + \"/val_ds_vit.pt\")\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "dataloader_train = DataLoader(TensorDataset(X_train, y_train.float()), \n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "dataloader_val =  DataLoader(TensorDataset(X_val, y_val.float()), \n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "\n",
        "model = NN_Classifier(768 * 6, 2048, 1).to(device)\n",
        "\n",
        "checkpoint_name = f\"vit\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "no_of_epoch = 100\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay=3e-4)\n",
        "scheduler = LinearLR(optimizer, start_factor=1, end_factor = 0.2, total_iters=50)\n",
        "start_epoch = 0\n",
        "early_stopper = EarlyStopper_Checkpoint(patience = 5, \n",
        "                                        save_path =  ROOT + f\"/{checkpoint_name}_best.pt\",\n",
        "                                        metric = \"val_acc\")\n",
        "bce_loss_func = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + no_of_epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Training \n",
        "    model.train()\n",
        "    for train_data, train_label in tqdm(dataloader_train):\n",
        "        train_data = combine_function(train_data[:,0,:], train_data[:,1,:])\n",
        "        optimizer.zero_grad()\n",
        "        output= model(train_data)\n",
        "        loss = bce_loss_func(output, train_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss = ema_loss(loss, train_loss)\n",
        "\n",
        "        y_pred = nn.Sigmoid()(output.detach())\n",
        "\n",
        "        correct += ((y_pred>0.5).float() == train_label).float().sum()\n",
        "\n",
        "    train_accuracy = correct / len(dataloader_train.dataset) * 100\n",
        "    checkpoint = {\"epoch\": epoch,\n",
        "                  \"model_state_dict\": model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'scheduler_state_dict': scheduler.state_dict()}\n",
        "    torch.save(checkpoint, ROOT + f\"/{checkpoint_name}.pt\")\n",
        "\n",
        "    print(f\"Saving checkpoint to {checkpoint_name}.pt\")\n",
        "    \n",
        "    correct = 0\n",
        "    val_loss = 0\n",
        "    \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for val_data, val_label in tqdm(dataloader_val):\n",
        "            val_data = combine_function(val_data[:,0,:], val_data[:,1,:])\n",
        "            output= model(val_data)\n",
        "            loss = bce_loss_func(output, val_label)\n",
        "            y_pred = nn.Sigmoid()(output)\n",
        "            val_loss = ema_loss(loss, val_loss)\n",
        "            correct += ((y_pred>0.5).float() == val_label).float().sum()\n",
        "\n",
        "        val_accuracy = correct / len(dataloader_val.dataset) * 100\n",
        "        print(f\"Epoch {epoch}: Train Loss: {train_loss: .5f}, Training Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss: .5f}, Val Accuracy = {val_accuracy:.2f}%\")\n",
        "\n",
        "    scheduler.step()\n",
        "    if early_stopper.check_metric(val_accuracy):\n",
        "        checkpoint = {\"epoch\": epoch,\n",
        "                      \"val_loss\": val_loss,\n",
        "                      \"val_accuracy\": val_accuracy,\n",
        "                      \"model_state_dict\": model.state_dict(),\n",
        "                      'optimizer_state_dict': optimizer.state_dict(),\n",
        "                      'scheduler_state_dict': scheduler.state_dict()}\n",
        "        \n",
        "        torch.save(checkpoint, ROOT + f\"/{checkpoint_name}_best.pt\")\n",
        "        print(f\"Saving checkpoint to {checkpoint_name}_best.pt\")\n",
        "\n",
        "\n",
        "    if early_stopper.early_stop(val_accuracy):\n",
        "        print(\"Stopped early due to no improvement in validation loss\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "_-325jJLVr2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Neural Network Classifier on all RESNet, SENet, and Vision Transformer Features**"
      ],
      "metadata": {
        "id": "u93D9yL1VdOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_1, y_train, X_val_1, y_val = load_data(ROOT + \"/train_ds_resnet.pt\", ROOT + \"/val_ds_resnet.pt\")\n",
        "X_train_2, _, X_val_2, _ = load_data(ROOT + \"/train_ds_senet.pt\", ROOT + \"/val_ds_senet.pt\")\n",
        "X_train_3, _, X_val_3, _ = load_data(ROOT + \"/train_ds_vit.pt\", ROOT + \"/val_ds_vit.pt\")\n",
        "\n",
        "X_train = torch.concat([X_train_1, X_train_2, X_train_3], dim = -1)\n",
        "X_val = torch.concat([X_val_1, X_val_2, X_val_3], dim = -1)\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "dataloader_train = DataLoader(TensorDataset(X_train, y_train.float()), \n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "dataloader_val =  DataLoader(TensorDataset(X_val, y_val.float()), \n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "\n",
        "model = NN_Classifier(4864 * 6, 1024, 1).to(device)\n",
        "\n",
        "checkpoint_name = f\"combined\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "no_of_epoch = 100\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay=3e-4)\n",
        "scheduler = LinearLR(optimizer, start_factor=1, end_factor = 0.2, total_iters=50)\n",
        "start_epoch = 0\n",
        "early_stopper = EarlyStopper_Checkpoint(patience = 5, \n",
        "                                        save_path =  ROOT + f\"/{checkpoint_name}_best.pt\",\n",
        "                                        metric = \"val_acc\")\n",
        "bce_loss_func = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + no_of_epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Training \n",
        "    model.train()\n",
        "    for train_data, train_label in tqdm(dataloader_train):\n",
        "        train_data = combine_function(train_data[:,0,:], train_data[:,1,:])\n",
        "        optimizer.zero_grad()\n",
        "        output= model(train_data)\n",
        "        loss = bce_loss_func(output, train_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss = ema_loss(loss, train_loss)\n",
        "\n",
        "        y_pred = nn.Sigmoid()(output.detach())\n",
        "\n",
        "        correct += ((y_pred>0.5).float() == train_label).float().sum()\n",
        "\n",
        "    train_accuracy = correct / len(dataloader_train.dataset) * 100\n",
        "    checkpoint = {\"epoch\": epoch,\n",
        "                  \"model_state_dict\": model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'scheduler_state_dict': scheduler.state_dict()}\n",
        "    torch.save(checkpoint, ROOT + f\"/{checkpoint_name}.pt\")\n",
        "\n",
        "    print(f\"Saving checkpoint to {checkpoint_name}.pt\")\n",
        "    \n",
        "    correct = 0\n",
        "    val_loss = 0\n",
        "    \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for val_data, val_label in tqdm(dataloader_val):\n",
        "            val_data = combine_function(val_data[:,0,:], val_data[:,1,:])\n",
        "            output= model(val_data)\n",
        "            loss = bce_loss_func(output, val_label)\n",
        "            y_pred = nn.Sigmoid()(output)\n",
        "            val_loss = ema_loss(loss, val_loss)\n",
        "            correct += ((y_pred>0.5).float() == val_label).float().sum()\n",
        "\n",
        "        val_accuracy = correct / len(dataloader_val.dataset) * 100\n",
        "        print(f\"Epoch {epoch}: Train Loss: {train_loss: .5f}, Training Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss: .5f}, Val Accuracy = {val_accuracy:.2f}%\")\n",
        "\n",
        "    scheduler.step()\n",
        "    if early_stopper.check_metric(val_accuracy):\n",
        "        checkpoint = {\"epoch\": epoch,\n",
        "                      \"val_loss\": val_loss,\n",
        "                      \"val_accuracy\": val_accuracy,\n",
        "                      \"model_state_dict\": model.state_dict(),\n",
        "                      'optimizer_state_dict': optimizer.state_dict(),\n",
        "                      'scheduler_state_dict': scheduler.state_dict()}\n",
        "        \n",
        "        torch.save(checkpoint, ROOT + f\"/{checkpoint_name}_best.pt\")\n",
        "        print(f\"Saving checkpoint to {checkpoint_name}_best.pt\")\n",
        "\n",
        "\n",
        "    if early_stopper.early_stop(val_accuracy):\n",
        "        print(\"Stopped early due to no improvement in validation loss\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "5Yjs-PyJU7oJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}